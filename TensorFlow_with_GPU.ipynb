{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/suzuki-tr/tensorflow-study/blob/master/TensorFlow_with_GPU.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "BlmQIFSLZDdc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "id": "3IEVK-KFxi5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8932b992-9c08-406b-acd2-f02cfd44e5b8"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C9fFcMTQF7Sw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e77a55f-5a91-4b5a-d45f-a29c9c697f26"
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.6.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "QXRh0DPiZRyG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "id": "t9ALbbpmY9rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d1e6f9ec-a453-4d01-b66d-b6e007c4ebb5"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "8.436719796999967\n",
            "GPU (s):\n",
            "0.8491997469999433\n",
            "GPU speedup over CPU: 9x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fz7Dz88TFQiW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create Multiple GRAPH and Use one of them in SESSION."
      ]
    },
    {
      "metadata": {
        "id": "P3j3q6FTFsj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "204fb8b0-c351-4b58-adb2-a68561590eef"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create multiple graph\n",
        "graph_1 = tf.Graph()\n",
        "with graph_1.as_default():\n",
        "  x = tf.placeholder(tf.float32, shape=[3],name='Input')\n",
        "  y = tf.square(x,name='Middle')\n",
        "  z = tf.square(y,name='Output')\n",
        "  print('graph_1',graph_1)\n",
        "\n",
        "graph_2 = tf.Graph()\n",
        "with graph_2.as_default():\n",
        "  x = tf.placeholder(tf.float32, shape=[3],name='Input')\n",
        "  c = tf.constant([1.0,1.0,1.0])\n",
        "  y = tf.add(x,c,name='Middle')\n",
        "  z = tf.add(y,c, name='Output')\n",
        "  print('graph_2',graph_2)\n",
        "\n",
        "# Use each graph\n",
        "with graph_1.as_default():\n",
        "  print('graph_1',tf.get_default_graph())\n",
        "  with tf.Session() as sess:\n",
        "    for op in sess.graph.get_operations():\n",
        "      print (op.name)\n",
        "    print (sess.run('Output:0', {'Input:0': [1.0, 2.0, 3.0]}))\n",
        "    print (sess.run('Output:0', {'Middle:0': [1.0, 2.0, 3.0]}))\n",
        "    print (sess.run('Middle:0', {'Input:0': [1.0, 2.0, 3.0]}))\n",
        "\n",
        "    \n",
        "with graph_2.as_default() as g:\n",
        "  print('graph_2',tf.get_default_graph())\n",
        "  with tf.Session() as sess:\n",
        "    for op in sess.graph.get_operations():\n",
        "      print (op.name)\n",
        "    print (sess.run('Output:0', {'Input:0': [1.0, 2.0, 3.0]}))\n",
        "    print (sess.run('Output:0', {'Middle:0': [1.0, 2.0, 3.0]}))\n",
        "    print (sess.run('Middle:0', {'Input:0': [1.0, 2.0, 3.0]}))\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph_1 <tensorflow.python.framework.ops.Graph object at 0x7f3a70eb2cc0>\n",
            "graph_2 <tensorflow.python.framework.ops.Graph object at 0x7f3a70eb2f98>\n",
            "graph_1 <tensorflow.python.framework.ops.Graph object at 0x7f3a70eb2cc0>\n",
            "Input\n",
            "Middle\n",
            "Output\n",
            "[ 1. 16. 81.]\n",
            "[1. 4. 9.]\n",
            "[1. 4. 9.]\n",
            "graph_2 <tensorflow.python.framework.ops.Graph object at 0x7f3a70eb2f98>\n",
            "Input\n",
            "Const\n",
            "Middle\n",
            "Output\n",
            "[3. 4. 5.]\n",
            "[2. 3. 4.]\n",
            "[2. 3. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vDfq-D95721G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "25da2973-df0c-4ad1-af4d-d6c5f146bfe7"
      },
      "cell_type": "code",
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default() as g:\n",
        " \n",
        "  c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n",
        "\n",
        "  # Already-used names will be \"uniquified\".\n",
        "  c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n",
        "\n",
        "  # Name scopes add a prefix to all operations created in the same context.\n",
        "  with tf.name_scope(\"outer\"):\n",
        "    c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n",
        "\n",
        "  # Name scopes nest like paths in a hierarchical file system.\n",
        "  with tf.name_scope(\"inner\"):\n",
        "    c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n",
        "\n",
        "  # Exiting a name scope context will return to the previous prefix.\n",
        "  c_4 = tf.constant(4, name=\"c\")  # => operation named \"outer/c_1\"\n",
        "\n",
        "  # Already-used name scopes will be \"uniquified\".\n",
        "  with tf.name_scope(\"inner\"):\n",
        "    c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\"\n",
        "  \n",
        "  for op in g.get_operations():\n",
        "    print(op.name)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c\n",
            "c_1\n",
            "outer/c\n",
            "inner/c\n",
            "c_2\n",
            "inner_1/c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWMWyjXU9Yrm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "d300afbb-5557-40ca-8c6f-c9db1d811881"
      },
      "cell_type": "code",
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default() as g:\n",
        "  x = tf.constant([[1.0, 2.0], [1.0, 2.0]])\n",
        "  w = tf.constant([[1.0, 1.0], [1.0, 1.0]])\n",
        "  y = tf.matmul(x, w)\n",
        "  output = tf.nn.softmax(y)\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    print(sess.run(x))\n",
        "    print(sess.run(w))\n",
        "    print(sess.run(output))\n",
        "    print(sess.run([y, output]))\n",
        "    #print(y_val, output_val)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 2.]\n",
            " [1. 2.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[0.5 0.5]\n",
            " [0.5 0.5]]\n",
            "[array([[3., 3.],\n",
            "       [3., 3.]], dtype=float32), array([[0.5, 0.5],\n",
            "       [0.5, 0.5]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}